import torch
import numpy as np
import pyaudio
import sys
import os
from transformers import (
    WhisperForConditionalGeneration,
    WhisperProcessor
)

# 1. ê²½ë¡œ ë° ì¥ì¹˜ ì„¤ì •
MODEL_PATH = "./whisper-tiny-finetuned"
device = "mps" if torch.backends.mps.is_available() else "cpu"

# 2. ëª¨ë¸ ë° í”„ë¡œì„¸ì„œ ë¡œë“œ
print(f"ğŸš€ íŒŒì¸íŠœë‹ ëª¨ë¸ ë¡œë“œ ì¤‘... (ì¥ì¹˜: {device})")
model = WhisperForConditionalGeneration.from_pretrained(MODEL_PATH).to(device)
processor = WhisperProcessor.from_pretrained(MODEL_PATH)

# â­ï¸ í•µì‹¬: ëª¨ë¸ ë‚´ë¶€ ì„¤ì •ì„ í•œêµ­ì–´ ë‹¤êµ­ì–´ ëª¨ë“œë¡œ ê°•ì œ ê³ ì •
model.config.forced_decoder_ids = None
model.config.suppress_tokens = []
model.config.is_multilingual = True

# 3. ì˜¤ë””ì˜¤ ì„¤ì •
FORMAT = pyaudio.paInt16
CHANNELS = 1
RATE = 16000
CHUNK = 1024 * 4
p = pyaudio.PyAudio()

stream = p.open(format=FORMAT, channels=CHANNELS, rate=RATE,
                input=True, frames_per_buffer=CHUNK)

print("\n" + "="*50)
print("ğŸ™ï¸  [í•œêµ­ì–´ ì „ìš©] ì‹¤ì‹œê°„ êµ°ì‚¬ ìš©ì–´ í…ŒìŠ¤íŠ¸ ì‹œì‘")
print("   (ì¢…ë£Œ: Ctrl+C)")
print("="*50 + "\n")

frames = []

try:
    while True:
        data = stream.read(CHUNK, exception_on_overflow=False)
        frames.append(np.frombuffer(data, dtype=np.int16))
        
        # ì•½ 2ì´ˆ(8ë²ˆì˜ CHUNK) ë°ì´í„°ê°€ ìŒ“ì´ë©´ ì¶”ë¡ 
        if len(frames) > 8: 
            audio_data = np.concatenate(frames).astype(np.float32) / 32768.0
            
            # íŠ¹ì§• ì¶”ì¶œ
            input_features = processor(audio_data, sampling_rate=RATE, return_tensors="pt").input_features.to(device)
            
            # â­ï¸ í•´ê²°ì±…: generate í˜¸ì¶œ ì‹œ languageì™€ taskë¥¼ ì§ì ‘ ì¸ìë¡œ ì „ë‹¬
            # ì´ë ‡ê²Œ í•˜ë©´ configì˜ ì˜¤ë¥˜ë‚˜ ë²„ì „ì„ ë¬´ì‹œí•˜ê³  í•œêµ­ì–´ë¡œ ê°•ì œ ì‹¤í–‰ë©ë‹ˆë‹¤.
            predicted_ids = model.generate(
                input_features,
                language="ko",
                task="transcribe",
                max_new_tokens=128,
                # Tiny ëª¨ë¸ì˜ í™˜ê° ë°©ì§€ë¥¼ ìœ„í•´ ë¹” ì„œì¹˜ ì¶”ê°€ (í•„ìš” ì‹œ 1ë¡œ ì¡°ì • ê°€ëŠ¥)
                num_beams=1 
            )
            
            transcription = processor.batch_decode(predicted_ids, skip_special_tokens=True)[0]
            
            if transcription.strip():
                # í•œê¸€ì´ í¬í•¨ëœ ê²½ìš°ì—ë§Œ ì¶œë ¥ (ì˜ì–´ í™˜ê° í•„í„°ë§ íš¨ê³¼)
                sys.stdout.write(f"\rğŸ“ ì¸ì‹ ê²°ê³¼: {transcription}                                ")
                sys.stdout.flush()
            
            frames = []

except KeyboardInterrupt:
    print("\n\n=== í…ŒìŠ¤íŠ¸ ì¢…ë£Œ ===")
finally:
    stream.stop_stream()
    stream.close()
    p.terminate()